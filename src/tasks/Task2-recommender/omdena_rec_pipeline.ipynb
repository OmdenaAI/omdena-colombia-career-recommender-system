{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc6bfd6",
   "metadata": {
    "papermill": {
     "duration": 0.041349,
     "end_time": "2021-10-17T23:57:18.288341",
     "exception": false,
     "start_time": "2021-10-17T23:57:18.246992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building a Modelling Pipeline\n",
    "\n",
    "One of the most important steps in Machine Learning is build a pipeline that allows you as a Data Scientist to Experiment, experiment and experiment. This is a crucial step saving time allowing to quickly make multiple experiments and minimizing the bugs on the ML systems you want to deploy. Let's begin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4c6237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:18.363003Z",
     "iopub.status.busy": "2021-10-17T23:57:18.362030Z",
     "iopub.status.idle": "2021-10-17T23:57:19.700787Z",
     "shell.execute_reply": "2021-10-17T23:57:19.700107Z",
     "shell.execute_reply.started": "2021-10-17T23:54:46.466591Z"
    },
    "papermill": {
     "duration": 1.380554,
     "end_time": "2021-10-17T23:57:19.700955",
     "exception": false,
     "start_time": "2021-10-17T23:57:18.320401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipe\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc52b2",
   "metadata": {
    "papermill": {
     "duration": 0.017624,
     "end_time": "2021-10-17T23:57:19.737826",
     "exception": false,
     "start_time": "2021-10-17T23:57:19.720202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking the data and data types\n",
    "\n",
    "One of the first thing we will do is check if our csv data types are correctly being interpreted by Pandas, why we care about this? It's easy not all objects take the same space in the computer, dtype `object` would take much more memory than dtype `int`. Also this dtypes would allow us to do specific operations. Let's read the file as it is and tune some of these dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cd3d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:19.779871Z",
     "iopub.status.busy": "2021-10-17T23:57:19.778630Z",
     "iopub.status.idle": "2021-10-17T23:57:19.786030Z",
     "shell.execute_reply": "2021-10-17T23:57:19.785542Z",
     "shell.execute_reply.started": "2021-10-17T23:55:10.675346Z"
    },
    "papermill": {
     "duration": 0.029321,
     "end_time": "2021-10-17T23:57:19.786155",
     "exception": false,
     "start_time": "2021-10-17T23:57:19.756834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_cols = ['your_birthdate']\n",
    "columns_scheme = {'your_dept_code_resides':'int',\n",
    "                 'your_municipality_code_resides':'int',\n",
    "                 'inst_institution_code':'int',\n",
    "                 'your_prgm_municipality_code':'int',\n",
    "                 'your_inst_municipality_code':'int',\n",
    "                 'your_inst_department_code':'int',\n",
    "                  'score_language_saber_11':'int',\n",
    "                  'score_mathematics_saber_11':'int',\n",
    "                  'score_biology_saber_11':'int',\n",
    "                  'score_chemistry_saber_11':'int',\n",
    "                  'score_physics_saber_11':'int',\n",
    "                  'score_social_science_saber_11':'int',\n",
    "                  'score_philosophy_saber_11':'int',\n",
    "                  'score_english_saber_11':'int',\n",
    "                 'score_optative_saber_11':'int'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b8f58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:19.827171Z",
     "iopub.status.busy": "2021-10-17T23:57:19.826527Z",
     "iopub.status.idle": "2021-10-17T23:57:27.337599Z",
     "shell.execute_reply": "2021-10-17T23:57:27.336957Z",
     "shell.execute_reply.started": "2021-10-17T23:55:12.002700Z"
    },
    "papermill": {
     "duration": 7.533964,
     "end_time": "2021-10-17T23:57:27.337745",
     "exception": false,
     "start_time": "2021-10-17T23:57:19.803781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212010 entries, 0 to 212009\n",
      "Data columns (total 98 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   your_type_of_document            212010 non-null  object \n",
      " 1   your_nationality                 212010 non-null  object \n",
      " 2   your_gender                      212010 non-null  object \n",
      " 3   your_birthdate                   212010 non-null  object \n",
      " 4   your_foreigner                   212010 non-null  object \n",
      " 5   period                           212010 non-null  int64  \n",
      " 6   your_consecutive                 212010 non-null  object \n",
      " 7   your_marital_status              212010 non-null  object \n",
      " 8   your_student                     212010 non-null  object \n",
      " 9   your_country_resides             212010 non-null  object \n",
      " 10  your_have_ethnicity              212010 non-null  object \n",
      " 11  your_dept_resides                212010 non-null  object \n",
      " 12  your_dept_code_resides           212010 non-null  int64  \n",
      " 13  your_municipality_resides        212010 non-null  object \n",
      " 14  your_municipality_code_resides   212010 non-null  int64  \n",
      " 15  your_high_school_degree          212010 non-null  object \n",
      " 16  your_tuition_cost_university     212010 non-null  object \n",
      " 17  your_tuition_pymt_scholarship    212010 non-null  object \n",
      " 18  your_tuition_pymt_credit         212010 non-null  object \n",
      " 19  your_tuition_pymt_parents        212010 non-null  object \n",
      " 20  your_tuition_pymt_yourself       212010 non-null  object \n",
      " 21  fami_current_household_type      212010 non-null  object \n",
      " 22  fami_is_the_head_family          212010 non-null  object \n",
      " 23  fami_econ_dependents             212010 non-null  object \n",
      " 24  fami_father_education            212010 non-null  object \n",
      " 25  fami_mother_education            212010 non-null  object \n",
      " 26  fami_father_occupation           212010 non-null  object \n",
      " 27  fami_mother_occupation           212010 non-null  object \n",
      " 28  fami_housing_stratum             212010 non-null  object \n",
      " 29  fami_internet                    212010 non-null  object \n",
      " 30  fami_computer                    212010 non-null  object \n",
      " 31  fami_automobile                  212010 non-null  object \n",
      " 32  fami_num_books                   212010 non-null  object \n",
      " 33  inst_institution_code            212010 non-null  int64  \n",
      " 34  inst_institution_name            212010 non-null  object \n",
      " 35  your_prgm_academic               212010 non-null  object \n",
      " 36  group_reference                  212010 non-null  object \n",
      " 37  your_prgm_municipality_code      212010 non-null  int64  \n",
      " 38  your_prgm_municipality           212010 non-null  object \n",
      " 39  your_prgm_department             212010 non-null  object \n",
      " 40  your_prgm_academic_level         212010 non-null  object \n",
      " 41  your_prgm_method                 212010 non-null  object \n",
      " 42  your_undergraduate_core          212010 non-null  object \n",
      " 43  your_inst_municipality_code      212010 non-null  int64  \n",
      " 44  your_inst_municipality           212010 non-null  object \n",
      " 45  your_inst_department             212010 non-null  object \n",
      " 46  inst_character_academic          212010 non-null  object \n",
      " 47  inst_origin                      212010 non-null  object \n",
      " 48  score_math_saber_pro             212010 non-null  float64\n",
      " 49  score_language_saber_pro         212010 non-null  float64\n",
      " 50  score_social_science_saber_pro   212010 non-null  float64\n",
      " 51  score_english_saber_pro          212010 non-null  float64\n",
      " 52  score_writing_saber_pro          212010 non-null  float64\n",
      " 53  your_state_research              212010 non-null  object \n",
      " 54  your_inst_department_code        212010 non-null  int64  \n",
      " 55  your_area_residse                212010 non-null  object \n",
      " 56  your_tuition                     212010 non-null  object \n",
      " 57  your_times_took_exam             212010 non-null  object \n",
      " 58  fami_social_stratum_sisben       212010 non-null  object \n",
      " 59  fami_house_members               212010 non-null  object \n",
      " 60  fami_house_rooms                 212010 non-null  object \n",
      " 61  fami_house_floor                 212010 non-null  object \n",
      " 62  fami_washer                      212010 non-null  object \n",
      " 63  fami_microwave                   212010 non-null  object \n",
      " 64  fami_oven                        212010 non-null  object \n",
      " 65  fami_dvd                         212010 non-null  object \n",
      " 66  fami_monthly_family_income       212010 non-null  object \n",
      " 67  your_currently_working           212010 non-null  object \n",
      " 68  your_background                  212010 non-null  object \n",
      " 69  cole_saber_11_icfes_code         212010 non-null  float64\n",
      " 70  cole_saber_11_icfes_dane         212010 non-null  float64\n",
      " 71  cole_saber_11_icfes_name         212010 non-null  object \n",
      " 72  cole_type                        212010 non-null  object \n",
      " 73  cole_nature                      212010 non-null  object \n",
      " 74  cole_calendar                    212010 non-null  object \n",
      " 75  cole_bilingual                   212010 non-null  object \n",
      " 76  cole_character                   212010 non-null  object \n",
      " 77  cole_dane_code_campus            212010 non-null  float64\n",
      " 78  cole_name_campus                 212010 non-null  object \n",
      " 79  cole_main_campus                 212010 non-null  object \n",
      " 80  cole_area_location               212010 non-null  object \n",
      " 81  cole_journey                     212010 non-null  object \n",
      " 82  cole_municipality_code_location  212010 non-null  float64\n",
      " 83  cole_municipality_location       212010 non-null  object \n",
      " 84  cole_dept_code_location          212010 non-null  float64\n",
      " 85  cole_dept_location               212010 non-null  object \n",
      " 86  score_language_saber_11          212010 non-null  int64  \n",
      " 87  score_mathematics_saber_11       212010 non-null  int64  \n",
      " 88  score_biology_saber_11           212010 non-null  int64  \n",
      " 89  score_chemistry_saber_11         212010 non-null  int64  \n",
      " 90  score_physics_saber_11           212010 non-null  int64  \n",
      " 91  score_social_science_saber_11    212010 non-null  int64  \n",
      " 92  score_philosophy_saber_11        212010 non-null  int64  \n",
      " 93  score_english_saber_11           212010 non-null  int64  \n",
      " 94  score_english_saber_11_category  212010 non-null  object \n",
      " 95  optative_field_saber_11          212010 non-null  object \n",
      " 96  score_optative_saber_11          212010 non-null  int64  \n",
      " 97  optative_category_saber_11       212010 non-null  object \n",
      "dtypes: float64(10), int64(16), object(72)\n",
      "memory usage: 158.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/saberpro-preprocessed/saber_combined_preprocessed.csv\", \n",
    "                 parse_dates=date_cols,\n",
    "                dtype=columns_scheme)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df59be1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:27.420737Z",
     "iopub.status.busy": "2021-10-17T23:57:27.413733Z",
     "iopub.status.idle": "2021-10-17T23:57:27.424621Z",
     "shell.execute_reply": "2021-10-17T23:57:27.425162Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.238065Z"
    },
    "papermill": {
     "duration": 0.066663,
     "end_time": "2021-10-17T23:57:27.425342",
     "exception": false,
     "start_time": "2021-10-17T23:57:27.358679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADMINISTRATION                                      35790\n",
       "LAW                                                 15263\n",
       "PUBLIC ACCOUNTING                                   14334\n",
       "EDUCATION                                           14219\n",
       "INDUSTRIAL ENGINEERING                              10660\n",
       "                                                    ...  \n",
       "NUTRITION AND DIET                                    264\n",
       "AGRICULTURAL, FOREST ENGINEERING                      244\n",
       "PHISICS                                               191\n",
       "TRAINING RELATED TO THE MILITARY OR POLICE FIELD      168\n",
       "REPRESENTATIVE ARTS                                   164\n",
       "Name: your_undergraduate_core, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['your_undergraduate_core'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f87e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:27.505981Z",
     "iopub.status.busy": "2021-10-17T23:57:27.504258Z",
     "iopub.status.idle": "2021-10-17T23:57:27.509026Z",
     "shell.execute_reply": "2021-10-17T23:57:27.508466Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.279868Z"
    },
    "papermill": {
     "duration": 0.063377,
     "end_time": "2021-10-17T23:57:27.509144",
     "exception": false,
     "start_time": "2021-10-17T23:57:27.445767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ADMINISTRATION', 'LAW', 'PUBLIC ACCOUNTING', 'EDUCATION',\n",
       "       'INDUSTRIAL ENGINEERING', 'PSYCHOLOGY',\n",
       "       'ENVIRONMENTAL, SANITARY ENGINEERING', 'UNCLASSIFIED',\n",
       "       'CIVIL ENGINEERING', 'SOCIAL COMMUNICATION, JOURNALISM', 'ECONOMY',\n",
       "       'COMPUTER SYSTEMS, TELEMATICS ENGINEERING', 'MECHANICAL ENGINEERING',\n",
       "       'DESIGN', 'ARCHITECTURE', 'SOCIOLOGY, SOCIAL WORK', 'NURSING',\n",
       "       'ELECTRONIC ENGINEERING, TELECOMMUNICATIONS', 'MEDICINE',\n",
       "       'SUPERIOR NORMALS', 'THERAPIES', 'MILITARY OR POLICE TRAINING',\n",
       "       'POLITICAL SCIENCE, INTERNATIONAL RELATIONS', 'CHEMICAL ENGINEERING',\n",
       "       'AGRONOMY', 'BIOLOGY, MICROBIOLOGY', 'MINING, METALLURGY ENGINEERING',\n",
       "       'PUBLIC HEALTH', 'OTHER ENGINEERING', 'VETERINARY MEDICINE',\n",
       "       'ADVERTISING', 'ELECTRICAL ENGINEERING', 'CHEMISTRY',\n",
       "       'SPORTS, PHYSICAL EDUCATION AND RECREATION',\n",
       "       'MODERN LANGUAGES, LITERATURE, LINGUISTICS', 'ODONTOLOGY',\n",
       "       'PLASTIC ARTS, VISUAL ARTS', 'SURGICAL INSTRUMENTATION', 'DENTISTRY',\n",
       "       'ZOOTECHNY', 'AGRONOMIC, LIVESTOCK ENGINEERING',\n",
       "       'ADMINISTRATIVE ENGINEERING', 'GEOGRAPHY, HISTORY', 'BACTERIOLOGY',\n",
       "       'GEOLOGY, OTHER NATURAL SCIENCE PROGRAMS', 'PLASTIC, VISUAL ARTS',\n",
       "       'LIBRARY, OTHERS OF SOCIAL AND HUMAN SCIENCES',\n",
       "       'BIOMEDICAL ENGINEERING', 'UNKNOWN',\n",
       "       'AGROINDUSTRIAL AND FOOD ENGINEERING',\n",
       "       'AGROINDUSTRIAL ENGINEERING, FOOD', 'MUSIC',\n",
       "       'ANTHROPOLOGY, LIBERAL ARTS', 'MATH, STATISTICS',\n",
       "       'OTHER PROGRAMS ASSOCIATED WITH FINE ARTS', 'PHILOSOPHY, THEOLOGY',\n",
       "       'NUTRITION AND DIETETICS', 'OPTOMETRY, OTHER HEALTH SCIENCE PROGRAMS',\n",
       "       'AGRICULTURAL, FORESTRY ENGINEERING', 'NUTRITION AND DIET',\n",
       "       'AGRICULTURAL, FOREST ENGINEERING', 'PHISICS',\n",
       "       'TRAINING RELATED TO THE MILITARY OR POLICE FIELD',\n",
       "       'REPRESENTATIVE ARTS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['your_undergraduate_core'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8d97dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:27.570575Z",
     "iopub.status.busy": "2021-10-17T23:57:27.569908Z",
     "iopub.status.idle": "2021-10-17T23:57:27.602928Z",
     "shell.execute_reply": "2021-10-17T23:57:27.602215Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.321693Z"
    },
    "papermill": {
     "duration": 0.074311,
     "end_time": "2021-10-17T23:57:27.603066",
     "exception": false,
     "start_time": "2021-10-17T23:57:27.528755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_dict = {'AGRICULTURAL, FORESTRY ENGINEERING':'AGRICULTURAL, FOREST ENGINEERING',\n",
    "               'AGROINDUSTRIAL ENGINEERING, FOOD':'AGROINDUSTRIAL AND FOOD ENGINEERING',\n",
    "               'TRAINING RELATED TO THE MILITARY OR POLICE FIELD':'MILITARY OR POLICE TRAINING',\n",
    "               'NUTRITION AND DIET':'NUTRITION AND DIETETICS'}\n",
    "df['your_undergraduate_core'] = df['your_undergraduate_core'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b22ce",
   "metadata": {
    "papermill": {
     "duration": 0.019075,
     "end_time": "2021-10-17T23:57:27.642202",
     "exception": false,
     "start_time": "2021-10-17T23:57:27.623127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Splitting into Train and Test\n",
    "\n",
    "Awesome with the data loaded it's time for our next step, when is our intention to model a ML algorithm we need to always **before we do anything else split between TRAIN and TEST datasets**.\n",
    "\n",
    "Why? It's because we want that our algorithm is able to generalize, the test data would then function as dataset to confidently said that our algorithm would do a great job when is in production. \n",
    "\n",
    "We would use SkLearn `train_test_split` function, within this function we will use a `random_state` this is for reproducibility of our ML Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577e98ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:27.692119Z",
     "iopub.status.busy": "2021-10-17T23:57:27.686575Z",
     "iopub.status.idle": "2021-10-17T23:57:28.067610Z",
     "shell.execute_reply": "2021-10-17T23:57:28.068087Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.380715Z"
    },
    "papermill": {
     "duration": 0.40722,
     "end_time": "2021-10-17T23:57:28.068266",
     "exception": false,
     "start_time": "2021-10-17T23:57:27.661046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "del(df) # Liberating ram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465203c",
   "metadata": {
    "papermill": {
     "duration": 0.019524,
     "end_time": "2021-10-17T23:57:28.107799",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.088275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-model pipeline\n",
    "\n",
    "Within this first pipeline we will define what would be our target (this would give us flexibility in case we want to later on change it), select the columns that we will use during training and drop the remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff10c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:28.158278Z",
     "iopub.status.busy": "2021-10-17T23:57:28.150442Z",
     "iopub.status.idle": "2021-10-17T23:57:28.166842Z",
     "shell.execute_reply": "2021-10-17T23:57:28.167462Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.741174Z"
    },
    "papermill": {
     "duration": 0.039536,
     "end_time": "2021-10-17T23:57:28.167596",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.128060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prepare',\n",
       "                 PrepareData(columns_to_model=['score_language_saber_11',\n",
       "                                               'score_mathematics_saber_11',\n",
       "                                               'score_biology_saber_11',\n",
       "                                               'score_chemistry_saber_11',\n",
       "                                               'score_physics_saber_11',\n",
       "                                               'score_social_science_saber_11',\n",
       "                                               'score_philosophy_saber_11',\n",
       "                                               'score_english_saber_11',\n",
       "                                               'optative_field_saber_11']))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_model =[\n",
    "    'score_language_saber_11',\n",
    "      'score_mathematics_saber_11',\n",
    "      'score_biology_saber_11',\n",
    "      'score_chemistry_saber_11',\n",
    "      'score_physics_saber_11',\n",
    "      'score_social_science_saber_11',\n",
    "      'score_philosophy_saber_11',\n",
    "      'score_english_saber_11',\n",
    "    'optative_field_saber_11']\n",
    "\n",
    "target = 'your_undergraduate_core'\n",
    "\n",
    "class PrepareData(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_model, target = 'your_undergraduate_core'):\n",
    "        self.target = target\n",
    "        self.columns_to_model = columns_to_model\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        y = X.loc[:, self.target]\n",
    "        X = X.loc[:, columns_to_model]\n",
    "        return X, y\n",
    "    \n",
    "prepare_data_pipe = Pipeline(steps=[('prepare',\n",
    "                                     PrepareData(columns_to_model=columns_to_model,\n",
    "                                                 target=target))])\n",
    "prepare_data_pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47d544",
   "metadata": {
    "papermill": {
     "duration": 0.020225,
     "end_time": "2021-10-17T23:57:28.207036",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.186811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can transform any raw data set, we do this in case we later on recieve more raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f72f3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:28.252683Z",
     "iopub.status.busy": "2021-10-17T23:57:28.250738Z",
     "iopub.status.idle": "2021-10-17T23:57:28.471605Z",
     "shell.execute_reply": "2021-10-17T23:57:28.471058Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.757741Z"
    },
    "papermill": {
     "duration": 0.244101,
     "end_time": "2021-10-17T23:57:28.471751",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.227650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data_pipe.transform(X_train)\n",
    "X_test, y_test = prepare_data_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b7be3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:28.517416Z",
     "iopub.status.busy": "2021-10-17T23:57:28.516439Z",
     "iopub.status.idle": "2021-10-17T23:57:28.529812Z",
     "shell.execute_reply": "2021-10-17T23:57:28.530356Z",
     "shell.execute_reply.started": "2021-10-17T23:55:19.976246Z"
    },
    "papermill": {
     "duration": 0.038611,
     "end_time": "2021-10-17T23:57:28.530498",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.491887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_language_saber_11</th>\n",
       "      <th>score_mathematics_saber_11</th>\n",
       "      <th>score_biology_saber_11</th>\n",
       "      <th>score_chemistry_saber_11</th>\n",
       "      <th>score_physics_saber_11</th>\n",
       "      <th>score_social_science_saber_11</th>\n",
       "      <th>score_philosophy_saber_11</th>\n",
       "      <th>score_english_saber_11</th>\n",
       "      <th>optative_field_saber_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139381</th>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>SCORE_DEEPEN_BIOLOGY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score_language_saber_11  score_mathematics_saber_11  \\\n",
       "139381                       56                          72   \n",
       "\n",
       "        score_biology_saber_11  score_chemistry_saber_11  \\\n",
       "139381                      66                        65   \n",
       "\n",
       "        score_physics_saber_11  score_social_science_saber_11  \\\n",
       "139381                      69                             62   \n",
       "\n",
       "        score_philosophy_saber_11  score_english_saber_11  \\\n",
       "139381                         56                      72   \n",
       "\n",
       "       optative_field_saber_11  \n",
       "139381    SCORE_DEEPEN_BIOLOGY  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d46011",
   "metadata": {
    "papermill": {
     "duration": 0.020118,
     "end_time": "2021-10-17T23:57:28.570495",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.550377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Pipeline \n",
    "\n",
    "In this section we're going to define a training pipeline, the pipeline would be able to recieve any X and y and train with the data within. For now we will just include a `OneHotEncoding` for the categorical variables and a `MinMaxScaler`. The power of these pipelines is that you can include any other transformation relatively easy. Just add a new tuple contaning a the name of the step and the SKLearn transformation method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10718fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:28.616676Z",
     "iopub.status.busy": "2021-10-17T23:57:28.615856Z",
     "iopub.status.idle": "2021-10-17T23:57:28.619289Z",
     "shell.execute_reply": "2021-10-17T23:57:28.619762Z",
     "shell.execute_reply.started": "2021-10-17T23:55:21.372412Z"
    },
    "papermill": {
     "duration": 0.029216,
     "end_time": "2021-10-17T23:57:28.619908",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.590692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['score_language_saber_11', 'score_mathematics_saber_11',\n",
       "       'score_biology_saber_11', 'score_chemistry_saber_11',\n",
       "       'score_physics_saber_11', 'score_social_science_saber_11',\n",
       "       'score_philosophy_saber_11', 'score_english_saber_11',\n",
       "       'optative_field_saber_11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92766fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:28.723617Z",
     "iopub.status.busy": "2021-10-17T23:57:28.722685Z",
     "iopub.status.idle": "2021-10-17T23:57:28.726178Z",
     "shell.execute_reply": "2021-10-17T23:57:28.725682Z",
     "shell.execute_reply.started": "2021-10-17T23:55:24.722070Z"
    },
    "papermill": {
     "duration": 0.085327,
     "end_time": "2021-10-17T23:57:28.726316",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.640989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SMOTE_strategy = {}\n",
    "for i in y_train.value_counts()[y_train.value_counts()<5000].index:\n",
    "    SMOTE_strategy[i] = 5000\n",
    "\n",
    "\n",
    "def ModelPipelineTrain(X_train, y_train, model, model_params):\n",
    "    '''\n",
    "    Recieves a X_train processed with it target values (y_train) and train a model\n",
    "    using SMOTE.\n",
    "    \n",
    "    You can also find the best model using a Random Search within a model_param dictonary\n",
    "    with all the hyperparameters to test\n",
    "    \n",
    "    Returns the \n",
    "    '''\n",
    "    \n",
    "    # Defining Categorical Pipeline\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse = True))\n",
    "    ])\n",
    "    \n",
    "    # Definining Numerical Pipeline\n",
    "    num_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "     \n",
    "    # Combine categorical and numerical pipelines\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('categorical', cat_pipeline, selector(dtype_exclude=\"float\")),\n",
    "        ('numerical', num_pipeline, selector(dtype_include=\"float\"))\n",
    "    ], remainder = 'drop')\n",
    "    \n",
    "    # Fit the processed data with a model\n",
    "    model_pipe = ImbPipe([\n",
    "        ('pre-process', preprocessor),\n",
    "        ('oversampling', SMOTE(random_state=42, n_jobs= -1, sampling_strategy=SMOTE_strategy)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Randomized Search\n",
    "    search = RandomizedSearchCV(model_pipe,\n",
    "                               model_params,\n",
    "                               cv = 5,\n",
    "                               verbose = 50,\n",
    "                                n_jobs = -1,\n",
    "                               scoring = 'recall_micro',\n",
    "                               random_state = 42,\n",
    "                               n_iter=8,\n",
    "                               )\n",
    "    # Fit\n",
    "    search.fit(X_train, y_train)\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b5f92cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T23:57:28.774598Z",
     "iopub.status.busy": "2021-10-17T23:57:28.773891Z",
     "iopub.status.idle": "2021-10-18T01:06:07.986506Z",
     "shell.execute_reply": "2021-10-18T01:06:07.986977Z"
    },
    "papermill": {
     "duration": 4119.238913,
     "end_time": "2021-10-18T01:06:07.987163",
     "exception": false,
     "start_time": "2021-10-17T23:57:28.748250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 47.7min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 51.4min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 55.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 56.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 60.0min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 60.7min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 61.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed: 63.4min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 64.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 64.7min finished\n"
     ]
    }
   ],
   "source": [
    "rf_params = {'model__max_depth':list(range(5,10)),\n",
    "            'model__n_estimators':[int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)],\n",
    "            }\n",
    "random_forest = ModelPipelineTrain(X_train, y_train, RandomForestClassifier(), rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca02ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T01:06:08.061225Z",
     "iopub.status.busy": "2021-10-18T01:06:08.060406Z",
     "iopub.status.idle": "2021-10-18T01:06:08.063656Z",
     "shell.execute_reply": "2021-10-18T01:06:08.062931Z",
     "shell.execute_reply.started": "2021-10-17T23:55:30.104389Z"
    },
    "papermill": {
     "duration": 0.042292,
     "end_time": "2021-10-18T01:06:08.063834",
     "exception": false,
     "start_time": "2021-10-18T01:06:08.021542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "joblib_file = \"rf_models.joblib\"  \n",
    "#dump(random_forest, joblib_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3eb9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T01:06:08.352964Z",
     "iopub.status.busy": "2021-10-18T01:06:08.348581Z",
     "iopub.status.idle": "2021-10-18T01:41:33.773674Z",
     "shell.execute_reply": "2021-10-18T01:41:33.772864Z",
     "shell.execute_reply.started": "2021-10-17T23:55:38.804490Z"
    },
    "papermill": {
     "duration": 2125.675356,
     "end_time": "2021-10-18T01:41:33.773858",
     "exception": false,
     "start_time": "2021-10-18T01:06:08.098502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.5min\n",
      "[CV] model__n_estimators=800, model__max_depth=6 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=6, score=0.169, total= 3.8min\n",
      "[CV] model__n_estimators=800, model__max_depth=6 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=6, score=0.169, total= 4.0min\n",
      "[CV] model__n_estimators=400, model__max_depth=8 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=8, score=0.169, total= 2.6min\n",
      "[CV] model__n_estimators=400, model__max_depth=8 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=8, score=0.169, total= 2.5min\n",
      "[CV] model__n_estimators=400, model__max_depth=8 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=8, score=0.169, total= 2.5min\n",
      "[CV] model__n_estimators=200, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=200, model__max_depth=5, score=0.169, total=  53.2s\n",
      "[CV] model__n_estimators=200, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=200, model__max_depth=5, score=0.169, total=  52.9s\n",
      "[CV] model__n_estimators=200, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=200, model__max_depth=5, score=0.169, total=  52.9s\n",
      "[CV] model__n_estimators=800, model__max_depth=9 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=9, score=0.169, total= 5.8min\n",
      "[CV] model__n_estimators=800, model__max_depth=9 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=9, score=0.169, total= 5.8min\n",
      "[CV] model__n_estimators=400, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=7, score=0.169, total= 2.2min\n",
      "[CV] model__n_estimators=400, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=7, score=0.169, total= 2.2min\n",
      "[CV] model__n_estimators=400, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=7, score=0.169, total= 2.2min\n",
      "[CV] model__n_estimators=400, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=7, score=0.169, total= 2.2min\n",
      "[CV] model__n_estimators=1000, model__max_depth=6 ....................\n",
      "[CV]  model__n_estimators=1000, model__max_depth=6, score=0.169, total= 4.6min\n",
      "[CV] model__n_estimators=1000, model__max_depth=6 ....................\n",
      "[CV]  model__n_estimators=1000, model__max_depth=6, score=0.169, total= 4.6min\n",
      "[CV] model__n_estimators=800, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=7, score=0.169, total= 4.3min\n",
      "[CV] model__n_estimators=800, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=7, score=0.169, total= 4.3min\n",
      "[CV] model__n_estimators=800, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=7, score=0.169, total= 4.3min\n",
      "[CV] model__n_estimators=400, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=5, score=0.169, total= 1.7min\n",
      "[CV] model__n_estimators=400, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=5, score=0.169, total= 1.7min\n",
      "[CV] model__max_depth=10, model__lambda=2, model__gamma=0, model__eta=0.5 \n",
      "[CV]  model__max_depth=10, model__lambda=2, model__gamma=0, model__eta=0.5, score=0.093, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.5min\n",
      "[CV] model__n_estimators=800, model__max_depth=6 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=6, score=0.169, total= 3.8min\n",
      "[CV] model__n_estimators=800, model__max_depth=6 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=6, score=0.169, total= 3.9min\n",
      "[CV] model__n_estimators=800, model__max_depth=6 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=6, score=0.169, total= 3.8min\n",
      "[CV] model__n_estimators=400, model__max_depth=8 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=8, score=0.169, total= 2.5min\n",
      "[CV] model__n_estimators=400, model__max_depth=8 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=8, score=0.169, total= 2.5min\n",
      "[CV] model__n_estimators=200, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=200, model__max_depth=5, score=0.169, total=  52.5s\n",
      "[CV] model__n_estimators=200, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=200, model__max_depth=5, score=0.169, total=  52.4s\n",
      "[CV] model__n_estimators=800, model__max_depth=9 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=9, score=0.169, total= 5.7min\n",
      "[CV] model__n_estimators=800, model__max_depth=9 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=9, score=0.169, total= 5.7min\n",
      "[CV] model__n_estimators=800, model__max_depth=9 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=9, score=0.169, total= 5.7min\n",
      "[CV] model__n_estimators=400, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=7, score=0.169, total= 2.2min\n",
      "[CV] model__n_estimators=1000, model__max_depth=6 ....................\n",
      "[CV]  model__n_estimators=1000, model__max_depth=6, score=0.169, total= 4.6min\n",
      "[CV] model__n_estimators=1000, model__max_depth=6 ....................\n",
      "[CV]  model__n_estimators=1000, model__max_depth=6, score=0.169, total= 4.6min\n",
      "[CV] model__n_estimators=1000, model__max_depth=6 ....................\n",
      "[CV]  model__n_estimators=1000, model__max_depth=6, score=0.169, total= 4.6min\n",
      "[CV] model__n_estimators=800, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=7, score=0.169, total= 4.3min\n",
      "[CV] model__n_estimators=800, model__max_depth=7 .....................\n",
      "[CV]  model__n_estimators=800, model__max_depth=7, score=0.169, total= 4.3min\n",
      "[CV] model__n_estimators=400, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=5, score=0.169, total= 1.7min\n",
      "[CV] model__n_estimators=400, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=5, score=0.169, total= 1.7min\n",
      "[CV] model__n_estimators=400, model__max_depth=5 .....................\n",
      "[CV]  model__n_estimators=400, model__max_depth=5, score=0.169, total= 1.3min\n",
      "[CV] model__max_depth=10, model__lambda=2, model__gamma=0, model__eta=0.5 \n",
      "[CV]  model__max_depth=10, model__lambda=2, model__gamma=0, model__eta=0.5, score=0.081, total= 1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 32.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed: 33.2min remaining:  1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 34.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 34.5min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'model__eta':[0.1, 0.3, 0.5],\n",
    "            'model__gamma':[0, 0.1, 10],\n",
    "            'model__max_depth':[3,6,10],\n",
    "            'model__lambda':[1, 2, 6, 10],\n",
    "            }\n",
    "xgb_model = ModelPipelineTrain(X_train, y_train, xgb.XGBClassifier(tree_method='gpu_hist', objective = 'multi:softprob', eval_metric='mlogloss'), xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a0ac9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T01:41:33.890683Z",
     "iopub.status.busy": "2021-10-18T01:41:33.889602Z",
     "iopub.status.idle": "2021-10-18T01:41:34.174144Z",
     "shell.execute_reply": "2021-10-18T01:41:34.174720Z",
     "shell.execute_reply.started": "2021-10-17T23:06:31.478259Z"
    },
    "papermill": {
     "duration": 0.345705,
     "end_time": "2021-10-18T01:41:34.174926",
     "exception": false,
     "start_time": "2021-10-18T01:41:33.829221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_models.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "joblib_file = \"xgb_models.joblib\"  \n",
    "dump(xgb_model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed1ff86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T01:41:34.305776Z",
     "iopub.status.busy": "2021-10-18T01:41:34.304698Z",
     "iopub.status.idle": "2021-10-18T01:42:58.982735Z",
     "shell.execute_reply": "2021-10-18T01:42:58.983247Z"
    },
    "papermill": {
     "duration": 84.753282,
     "end_time": "2021-10-18T01:42:58.983473",
     "exception": false,
     "start_time": "2021-10-18T01:41:34.230191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model Report --\n",
      "Accuracy: 0.16987995849252394\n",
      "Recall (Micro): 0.16987995849252394\n",
      "F1-Score (Micro): 0.16987995849252394\n",
      "-- Model Report --\n",
      "Accuracy: 0.16824678081222583\n",
      "Recall (Micro): 0.16824678081222583\n",
      "F1-Score (Micro): 0.16824678081222583\n"
     ]
    }
   ],
   "source": [
    "def model_report(model, X_infer, y_true):\n",
    "    print('-- Model Report --')\n",
    "    y_pred = model.predict(X_infer)\n",
    "    print('Accuracy: '+str(accuracy_score(y_true, y_pred)))\n",
    "    print('Recall (Micro): '+str(recall_score(y_true, y_pred,average='micro')))\n",
    "    print('F1-Score (Micro): '+str(f1_score(y_true, y_pred,average='micro')))\n",
    "\n",
    "model_report(random_forest.best_estimator_, X_train, y_train)\n",
    "model_report(random_forest.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27466a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T01:42:59.110645Z",
     "iopub.status.busy": "2021-10-18T01:42:59.101513Z",
     "iopub.status.idle": "2021-10-18T01:43:16.455135Z",
     "shell.execute_reply": "2021-10-18T01:43:16.454235Z"
    },
    "papermill": {
     "duration": 17.41701,
     "end_time": "2021-10-18T01:43:16.455364",
     "exception": false,
     "start_time": "2021-10-18T01:42:59.038354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model Report --\n",
      "Accuracy: 0.1598627423234753\n",
      "Recall (Micro): 0.1598627423234753\n",
      "F1-Score (Micro): 0.1598627423234753\n",
      "-- Model Report --\n",
      "Accuracy: 0.15895476628460922\n",
      "Recall (Micro): 0.15895476628460922\n",
      "F1-Score (Micro): 0.15895476628460922\n"
     ]
    }
   ],
   "source": [
    "model_report(xgb_model.best_estimator_, X_train, y_train)\n",
    "model_report(xgb_model.best_estimator_, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6368.132145,
   "end_time": "2021-10-18T01:43:17.649900",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-17T23:57:09.517755",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
