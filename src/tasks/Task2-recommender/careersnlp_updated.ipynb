{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nltk==3.4\n!pip install yellowbrick -U\n!pip install gensim==3.6.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import base64\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Plotly imports\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\npy.init_notebook_mode(connected=True)\n\n# Other imports\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import NMF, LatentDirichletAllocation\nimport json\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.util import ngrams\nimport string\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_rows', 200) # to show more rows.\n\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-09T18:22:10.788665Z","iopub.execute_input":"2021-11-09T18:22:10.788972Z","iopub.status.idle":"2021-11-09T18:22:10.861471Z","shell.execute_reply.started":"2021-11-09T18:22:10.788939Z","shell.execute_reply":"2021-11-09T18:22:10.860759Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"References :\n1. https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n2. https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n3. https://github.com/ElizaLo/NLP-Natural-Language-Processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_json('../input/careerdb/database.json')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:08:30.912001Z","iopub.execute_input":"2021-11-09T18:08:30.912278Z","iopub.status.idle":"2021-11-09T18:08:31.025119Z","shell.execute_reply.started":"2021-11-09T18:08:30.912251Z","shell.execute_reply":"2021-11-09T18:08:31.023886Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.rename(columns={'pregrado':'undergraduate',\n                   'Universidad':'university',\n                   'detalles':'details',\n                   'Descripcion':'description',\n                  'Registro calificado':'Qualified record',\n                  'Nivel de formación':'Level of Education',\n                  'Tipo de formación':'Type of training',\n                  'Título otorgado':'Title awarded',\n                  'Modalidad':'Modality',\n                  'Duración':'Duration',\n                  'Créditos':'Credits',\n                  'Ciudad':'Town'},inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:11:32.258833Z","iopub.execute_input":"2021-11-09T18:11:32.259120Z","iopub.status.idle":"2021-11-09T18:11:32.329943Z","shell.execute_reply.started":"2021-11-09T18:11:32.259091Z","shell.execute_reply":"2021-11-09T18:11:32.329300Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def nan_check(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent_1 = data.isnull().sum()/data.isnull().count()*100\n    percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n    return missing_data\n\nnan_check(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:21:25.461228Z","iopub.execute_input":"2021-11-09T18:21:25.462384Z","iopub.status.idle":"2021-11-09T18:21:25.544678Z","shell.execute_reply.started":"2021-11-09T18:21:25.462309Z","shell.execute_reply":"2021-11-09T18:21:25.543652Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T16:28:14.60075Z","iopub.execute_input":"2021-11-08T16:28:14.601039Z","iopub.status.idle":"2021-11-08T16:28:14.619924Z","shell.execute_reply.started":"2021-11-08T16:28:14.601009Z","shell.execute_reply":"2021-11-08T16:28:14.619092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.undergraduate.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:23:10.128918Z","iopub.execute_input":"2021-11-09T18:23:10.129235Z","iopub.status.idle":"2021-11-09T18:23:10.184904Z","shell.execute_reply.started":"2021-11-09T18:23:10.129204Z","shell.execute_reply":"2021-11-09T18:23:10.183981Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Delete .....\ndf1 = df[(df['undergraduate'].str.find('especializacion')==-1) &\n    (df['undergraduate'].str.find('maestria')==-1) & \n    (df['undergraduate'].str.find('doctorado')==-1) & \n    (df['undergraduate'].str.find('tecnologia')==-1)]\n\ndf1.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:23:52.870508Z","iopub.execute_input":"2021-11-09T18:23:52.870782Z","iopub.status.idle":"2021-11-09T18:23:52.947290Z","shell.execute_reply.started":"2021-11-09T18:23:52.870753Z","shell.execute_reply":"2021-11-09T18:23:52.946418Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df1.undergraduate.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_str(x):\n    if (str(x).find('administracion') != -1) or (str(x).find('contaduria') != -1) \\\n    or (str(x).find('economia') != -1) or (str(x).find('negocios') != -1) \\\n    or (str(x).find('mercadeo') != -1) or (str(x).find('finanzas') != -1) \\\n    or (str(x).find('publicidad') != -1) or (str(x).find('comercio') != -1):\n        return 'BUSINESS'\n    elif str(x).find('ingenieria') != -1:\n        return 'ENGINEERING'\n    elif (str(x).find('derecho') != -1)   or (str(x).find('psico') != -1) \\\n    or (str(x).find('comunicacion') != -1) or (str(x).find('social') != -1) \\\n    or (str(x).find('pedagogia') != -1) or (str(x).find('filosofia') != -1) \\\n    or (str(x).find('educacion infantil') != -1) or (str(x).find('teologia') != -1) \\\n    or (str(x).find('antropologia') != -1) or (str(x).find('ciencia politica') != -1) \\\n    or (str(x).find('historia') != -1) or (str(x).find('sociologia') != -1) \\\n    or (str(x).find('literatura') != -1) or (str(x).find('ciencias politicas') != -1) \\\n    or (str(x).find('relaciones internacionales') != -1):\n        return 'HUMANITIES AND SOCIAL SCIENCE'\n    elif (str(x).find('medicina') != -1) or (str(x).find('enfermeria') != -1) \\\n    or (str(x).find('odontologia') != -1) or (str(x).find('salud en el trabajo') != -1) \\\n    or (str(x).find('quirurgica') != -1) :\n        return 'HEALTH & MEDICINE'\n    elif (str(x).find('educacion fisica') != -1) or (str(x).find('fisioterapia') != -1):\n        return 'SPORTS AND PHYSICAL TRAIN'\n    elif (str(x).find('arquitectura') != -1) or (str(x).find('music') != -1) \\\n    or (str(x).find('diseño') != -1) or (str(x).find('artes') != -1) \\\n    or (str(x).find('fotografia') != -1):\n        return 'ARTS AND DESIGN'\n    elif (str(x).find('matematicas') != -1) or (str(x).find('fisica') != -1) \\\n    or (str(x).find('estadistica') != -1) or (str(x).find('biologia') != -1) \\\n    or (str(x).find('ciencias naturales') != -1) or (str(x).find('quimica') != -1) :\n        return 'MATH AND PHYSICAL SCIENCES'\n    else:\n        return 'OTHER'","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:24:13.695103Z","iopub.execute_input":"2021-11-09T18:24:13.695776Z","iopub.status.idle":"2021-11-09T18:24:13.753563Z","shell.execute_reply.started":"2021-11-09T18:24:13.695737Z","shell.execute_reply":"2021-11-09T18:24:13.752619Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df1['final_cat'] = df1['undergraduate'].apply(replace_str)\ndf1['final_cat'].value_counts(normalize = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:24:18.532147Z","iopub.execute_input":"2021-11-09T18:24:18.533440Z","iopub.status.idle":"2021-11-09T18:24:18.588350Z","shell.execute_reply.started":"2021-11-09T18:24:18.533368Z","shell.execute_reply":"2021-11-09T18:24:18.587446Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Droping OTHER Undergraduate\ndf1 = df1[df1['final_cat'] != 'OTHER']\n# Dropping void Description\ndf1= df1[df1['description']!='']\n# replacing big space\ndf1['description'] = df1['description'].str.strip('').replace('  ', ' ')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:24:36.523587Z","iopub.execute_input":"2021-11-09T18:24:36.523892Z","iopub.status.idle":"2021-11-09T18:24:36.575307Z","shell.execute_reply.started":"2021-11-09T18:24:36.523861Z","shell.execute_reply":"2021-11-09T18:24:36.573972Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df1.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:24:41.559244Z","iopub.execute_input":"2021-11-09T18:24:41.559843Z","iopub.status.idle":"2021-11-09T18:24:41.626791Z","shell.execute_reply.started":"2021-11-09T18:24:41.559770Z","shell.execute_reply":"2021-11-09T18:24:41.625600Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data = [go.Bar(\n            x = df1.final_cat.unique(),\n            y = df1.final_cat.value_counts().values,\n            marker= dict(colorscale='Jet',\n                         color = df1.final_cat.value_counts().values\n                        ),\n            text='Text entries attributed to Final Category'\n    )]\n\nlayout = go.Layout(\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:24:43.055760Z","iopub.execute_input":"2021-11-09T18:24:43.056454Z","iopub.status.idle":"2021-11-09T18:24:44.121503Z","shell.execute_reply.started":"2021-11-09T18:24:43.056411Z","shell.execute_reply":"2021-11-09T18:24:44.120755Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data = [go.Bar(\n            x = df1.undergraduate.unique(),\n            y = df1.undergraduate.value_counts().values,\n            marker= dict(colorscale='Jet',\n                         color = df1.undergraduate.value_counts().values\n                        ),\n            text='Text entries attributed to undergraduate Category'\n    )]\n\nlayout = go.Layout(\n    title='Undergraduate variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:25:28.807204Z","iopub.execute_input":"2021-11-09T18:25:28.807660Z","iopub.status.idle":"2021-11-09T18:25:28.901386Z","shell.execute_reply.started":"2021-11-09T18:25:28.807627Z","shell.execute_reply":"2021-11-09T18:25:28.900550Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"all_words = df1['undergraduate'].str.split(expand=True).unstack().value_counts()\ndata = [go.Bar(\n            x = all_words.index.values[2:50],\n            y = all_words.values[2:50],\n            marker= dict(colorscale='Jet',\n                         color = all_words.values[2:100]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 (Uncleaned) Word frequencies in the Undergraduate'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:26:12.490842Z","iopub.execute_input":"2021-11-09T18:26:12.491125Z","iopub.status.idle":"2021-11-09T18:26:12.621083Z","shell.execute_reply.started":"2021-11-09T18:26:12.491094Z","shell.execute_reply":"2021-11-09T18:26:12.619969Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"all_words = df1['description'].str.split(expand=True).unstack().value_counts()\ndata = [go.Bar(\n            x = all_words.index.values[2:50],\n            y = all_words.values[2:50],\n            marker= dict(colorscale='Jet',\n                         color = all_words.values[2:100]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 (Uncleaned) Word frequencies in the Description'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:26:13.804930Z","iopub.execute_input":"2021-11-09T18:26:13.805263Z","iopub.status.idle":"2021-11-09T18:26:14.006771Z","shell.execute_reply.started":"2021-11-09T18:26:13.805223Z","shell.execute_reply":"2021-11-09T18:26:14.005709Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"all_words = df1['university'].str.split(expand=True).unstack().value_counts()\ndata = [go.Bar(\n            x = all_words.index.values[2:50],\n            y = all_words.values[2:50],\n            marker= dict(colorscale='Jet',\n                         color = all_words.values[2:100]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 (Uncleaned) Word frequencies in the University'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:26:25.812213Z","iopub.execute_input":"2021-11-09T18:26:25.812786Z","iopub.status.idle":"2021-11-09T18:26:25.936612Z","shell.execute_reply.started":"2021-11-09T18:26:25.812748Z","shell.execute_reply":"2021-11-09T18:26:25.935268Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"stopwords_new = ['universidad','programa',\n                 'formacion','desarrollo','profesionales',\n                 'colombia', 'estudiante', 'quindio', 'cooperativa', 'santo', 'tomas',\n                 'sergio','arboleda','pontificia','bolivariana']","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:26:45.494110Z","iopub.execute_input":"2021-11-09T18:26:45.494574Z","iopub.status.idle":"2021-11-09T18:26:45.548402Z","shell.execute_reply.started":"2021-11-09T18:26:45.494517Z","shell.execute_reply":"2021-11-09T18:26:45.547040Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')\nspanish_stopwords = stopwords.words('spanish')\nspanish_stopwords.extend(stopwords_new)\n\ndef tokenize(sentence):\n    return [token for token in nltk.word_tokenize(sentence)]\ndef remove_stopwords(sentence):\n    return [token for token in nltk.word_tokenize(sentence) if (token.lower() not in spanish_stopwords) and (token.lower() !=' ') and (token not in string.punctuation)]","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:26:46.681881Z","iopub.execute_input":"2021-11-09T18:26:46.682195Z","iopub.status.idle":"2021-11-09T18:26:47.112325Z","shell.execute_reply.started":"2021-11-09T18:26:46.682148Z","shell.execute_reply":"2021-11-09T18:26:47.111427Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df1['token'] = df1['description'].apply(lambda x: tokenize(x))\ndf1['token_no_stopwords'] = df1['description'].apply(lambda x: remove_stopwords(x))\ndf1['bigram'] = df1['token_no_stopwords'].apply(lambda x: list(ngrams(x, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:26:58.245692Z","iopub.execute_input":"2021-11-09T18:26:58.246001Z","iopub.status.idle":"2021-11-09T18:27:00.163967Z","shell.execute_reply.started":"2021-11-09T18:26:58.245973Z","shell.execute_reply":"2021-11-09T18:27:00.162987Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:27:30.779428Z","iopub.execute_input":"2021-11-09T18:27:30.779940Z","iopub.status.idle":"2021-11-09T18:27:30.911645Z","shell.execute_reply.started":"2021-11-09T18:27:30.779888Z","shell.execute_reply":"2021-11-09T18:27:30.910605Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(stop_words=spanish_stopwords)\nX = vectorizer.fit_transform(df1['description'])\nmodel = KMeans( init='k-means++', max_iter=400, random_state=2021,)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:28:39.869783Z","iopub.execute_input":"2021-11-09T18:28:39.870106Z","iopub.status.idle":"2021-11-09T18:28:40.008968Z","shell.execute_reply.started":"2021-11-09T18:28:39.870073Z","shell.execute_reply":"2021-11-09T18:28:40.007579Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:28:56.033092Z","iopub.execute_input":"2021-11-09T18:28:56.033517Z","iopub.status.idle":"2021-11-09T18:28:56.095275Z","shell.execute_reply.started":"2021-11-09T18:28:56.033454Z","shell.execute_reply":"2021-11-09T18:28:56.094362Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from yellowbrick.cluster import KElbowVisualizer\n\n# k is range of number of clusters.\nvisualizer = KElbowVisualizer(model, k=(2,10), timings= True,)\nvisualizer.fit(X)        # Fit data to visualizer\nvisualizer.show()        # Finalize and render figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:28:59.555893Z","iopub.execute_input":"2021-11-09T18:28:59.556194Z","iopub.status.idle":"2021-11-09T18:29:06.395407Z","shell.execute_reply.started":"2021-11-09T18:28:59.556162Z","shell.execute_reply":"2021-11-09T18:29:06.394473Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"visualizer = KElbowVisualizer(model, k=(2,10), metric='silhouette', timings= True)\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:29:06.399829Z","iopub.execute_input":"2021-11-09T18:29:06.400226Z","iopub.status.idle":"2021-11-09T18:29:12.791420Z","shell.execute_reply.started":"2021-11-09T18:29:06.400179Z","shell.execute_reply":"2021-11-09T18:29:12.790639Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"n_clusters = 7\n\ndef get_clusters_top_words(n_clusters):\n    model = KMeans(n_clusters, init='k-means++', max_iter=400, random_state=2021)\n    model.fit(X)\n    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n    terms = vectorizer.get_feature_names()\n\n    for i in range(n_clusters):\n        print('Cluster %d:' % i),\n        for ind in order_centroids[i, :5]:\n            print(' %s' % terms[ind])\n\nget_clusters_top_words(7)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:29:27.564970Z","iopub.execute_input":"2021-11-09T18:29:27.565569Z","iopub.status.idle":"2021-11-09T18:29:28.478896Z","shell.execute_reply.started":"2021-11-09T18:29:27.565531Z","shell.execute_reply":"2021-11-09T18:29:28.478018Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"get_clusters_top_words(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:29:37.418675Z","iopub.execute_input":"2021-11-09T18:29:37.419008Z","iopub.status.idle":"2021-11-09T18:29:37.960359Z","shell.execute_reply.started":"2021-11-09T18:29:37.418976Z","shell.execute_reply":"2021-11-09T18:29:37.959251Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nbigram_list = [pair for row in df1['token_no_stopwords'] for pair in ngrams(row, 2)]\nbigram = Counter(bigram_list).most_common()\nbigram = pd.DataFrame.from_records(bigram, columns=['gram', 'count'])\nbigram[:20]","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:29:42.560128Z","iopub.execute_input":"2021-11-09T18:29:42.560771Z","iopub.status.idle":"2021-11-09T18:29:42.677143Z","shell.execute_reply.started":"2021-11-09T18:29:42.560659Z","shell.execute_reply":"2021-11-09T18:29:42.676211Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"words = (df1['token_no_stopwords'].apply(lambda x: ' '.join(x))).str.cat(sep=' ').split()\nCounter(words).most_common(50)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:29:55.191758Z","iopub.execute_input":"2021-11-09T18:29:55.192403Z","iopub.status.idle":"2021-11-09T18:29:55.261071Z","shell.execute_reply.started":"2021-11-09T18:29:55.192347Z","shell.execute_reply":"2021-11-09T18:29:55.260179Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import re\ndata = df1['token_no_stopwords'].str.join(' ').values.tolist()\ndata = [re.sub('\\s+', ' ', sent) for sent in data] # Remove new line characters\ndata = [re.sub(\"\\'\", \"\", sent) for sent in data] # Remove distracting single quotes","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:30:44.878460Z","iopub.execute_input":"2021-11-09T18:30:44.878760Z","iopub.status.idle":"2021-11-09T18:30:44.956947Z","shell.execute_reply.started":"2021-11-09T18:30:44.878731Z","shell.execute_reply":"2021-11-09T18:30:44.955848Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:30:50.888818Z","iopub.execute_input":"2021-11-09T18:30:50.889382Z","iopub.status.idle":"2021-11-09T18:30:50.943904Z","shell.execute_reply.started":"2021-11-09T18:30:50.889310Z","shell.execute_reply":"2021-11-09T18:30:50.942954Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n\n# spacy for lemmatization\nimport spacy\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:31:27.503946Z","iopub.execute_input":"2021-11-09T18:31:27.504247Z","iopub.status.idle":"2021-11-09T18:31:40.926674Z","shell.execute_reply.started":"2021-11-09T18:31:27.504213Z","shell.execute_reply":"2021-11-09T18:31:40.924560Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def sentence_to_words(sentences):\n    for sentence in sentences:\n        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n\ndata_words = list(sentence_to_words(data))\nprint(data_words[:1])","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:31:40.930171Z","iopub.execute_input":"2021-11-09T18:31:40.930426Z","iopub.status.idle":"2021-11-09T18:31:41.216212Z","shell.execute_reply.started":"2021-11-09T18:31:40.930396Z","shell.execute_reply":"2021-11-09T18:31:41.215290Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Creating Bigram and Trigram Models","metadata":{}},{"cell_type":"code","source":"# Build the bigram and trigram models\nbigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\ntrigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n\n# Faster way to get a sentence clubbed as a trigram/bigram\nbigram_mod = gensim.models.phrases.Phraser(bigram)\ntrigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# See trigram example\nprint(trigram_mod[bigram_mod[data_words[0]]])","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:31:51.329611Z","iopub.execute_input":"2021-11-09T18:31:51.330085Z","iopub.status.idle":"2021-11-09T18:31:52.348933Z","shell.execute_reply.started":"2021-11-09T18:31:51.329917Z","shell.execute_reply":"2021-11-09T18:31:52.347645Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Remove Stopwords, Make Bigrams and Lemmatize\n\nThe bigrams model is ready. Let’s define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially.","metadata":{}},{"cell_type":"code","source":"def remove_stopwords(texts):\n    return [[word for word in simple_preprocess(str(doc)) if word not in spanish_stopwords] for doc in texts]\n\ndef make_bigrams(texts):\n    return [bigram_mod[doc] for doc in texts]\n\ndef make_trigrams(texts):\n    return [trigram_mod[bigram_mod[doc]] for doc in texts]","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:32:00.293395Z","iopub.execute_input":"2021-11-09T18:32:00.293882Z","iopub.status.idle":"2021-11-09T18:32:00.386288Z","shell.execute_reply.started":"2021-11-09T18:32:00.293831Z","shell.execute_reply":"2021-11-09T18:32:00.385504Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \"\"\"https://spacy.io/api/annotation\"\"\"\n    texts_out = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    return texts_out","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:32:01.848604Z","iopub.execute_input":"2021-11-09T18:32:01.849244Z","iopub.status.idle":"2021-11-09T18:32:01.947108Z","shell.execute_reply.started":"2021-11-09T18:32:01.849205Z","shell.execute_reply":"2021-11-09T18:32:01.945917Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download es_core_news_sm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import es_core_news_sm\n\n# Remove Stop Words\ndata_words_nostops = remove_stopwords(data_words)\n\n# Form Bigrams\ndata_words_bigrams = make_bigrams(data_words_nostops)\n\n# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n# python3 -m spacy download en\nnlp = es_core_news_sm.load()\n\n# Do lemmatization\ndata_lemmatized = lemmatization(data_words_bigrams)\n\nprint(data_lemmatized[:1])","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:32:25.591785Z","iopub.execute_input":"2021-11-09T18:32:25.592777Z","iopub.status.idle":"2021-11-09T18:32:37.254943Z","shell.execute_reply.started":"2021-11-09T18:32:25.592722Z","shell.execute_reply":"2021-11-09T18:32:37.253744Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Create the Dictionary and Corpus needed for Topic Modeling","metadata":{}},{"cell_type":"code","source":"# Create Dictionary\nid2word = corpora.Dictionary(data_lemmatized)\n\n# Create Corpus\ntexts = data_lemmatized\n\n# Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in texts]\n\n# View\nprint(corpus[:1])","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:32:40.623021Z","iopub.execute_input":"2021-11-09T18:32:40.623527Z","iopub.status.idle":"2021-11-09T18:32:40.785558Z","shell.execute_reply.started":"2021-11-09T18:32:40.623447Z","shell.execute_reply":"2021-11-09T18:32:40.784669Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:5]]","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:32:48.554091Z","iopub.execute_input":"2021-11-09T18:32:48.554670Z","iopub.status.idle":"2021-11-09T18:32:48.650342Z","shell.execute_reply.started":"2021-11-09T18:32:48.554632Z","shell.execute_reply":"2021-11-09T18:32:48.649601Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Building the Topic Model\n\n* We have everything required to train the LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well.\n\n* Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior.\n\n* chunksize is the number of documents to be used in each training chunk. update_every determines how often the model parameters should be updated and passes is the total number of training passes.","metadata":{}},{"cell_type":"code","source":"# Build LDA model\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, # corpus\n                                           id2word=id2word, # index to word\n                                           num_topics=7,  # \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View the topics in LDA model","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(action='ignore',category=UserWarning,module='gensim')  \nwarnings.filterwarnings(action='ignore',category=FutureWarning,module='gensim') ","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:35:20.145744Z","iopub.execute_input":"2021-11-09T18:35:20.146402Z","iopub.status.idle":"2021-11-09T18:35:20.254251Z","shell.execute_reply.started":"2021-11-09T18:35:20.146356Z","shell.execute_reply":"2021-11-09T18:35:20.253138Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nbest_model = None\ntop_score = 0\nfor x in range(1,16):\n    print(f'Number of topics:{x}')\n    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=x, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)\n    \n    # Compute Perplexity\n    print(f'Perplexity for {x} topics: {lda_model.log_perplexity(corpus)}')  # a measure of how good the model is. lower the better.\n\n    # Compute Coherence Score\n    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n    coherence_lda = coherence_model_lda.get_coherence()\n    print(f'Coherence Score for {x} topics: {coherence_lda} \\n')\n    if coherence_lda > top_score:\n        best_model = x\n        top_score = coherence_lda\nprint(f'\\nBest Results with {best_model} topics with a Coherence of {top_score}')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:36:41.733482Z","iopub.execute_input":"2021-11-09T18:36:41.733821Z","iopub.status.idle":"2021-11-09T18:38:12.316904Z","shell.execute_reply.started":"2021-11-09T18:36:41.733777Z","shell.execute_reply":"2021-11-09T18:38:12.315519Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"**Topic 14**\n* Perplexity:  -7.653208814753565\n\n* Coherence Score:  0.40041877333075954\n\n**There we have a coherence score of 0.40.**","metadata":{}},{"cell_type":"markdown","source":"# Compute Model Perplexity and Coherence Score\n\nModel perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. In my experience, topic coherence score, in particular, has been more helpful.","metadata":{}},{"cell_type":"code","source":"# Compute Perplexity\nprint('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:38:36.655188Z","iopub.execute_input":"2021-11-09T18:38:36.655516Z","iopub.status.idle":"2021-11-09T18:38:38.884314Z","shell.execute_reply.started":"2021-11-09T18:38:36.655466Z","shell.execute_reply":"2021-11-09T18:38:38.883258Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the topics-keywords using pyLDAvis","metadata":{}},{"cell_type":"code","source":"# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\nvis","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:38:54.158960Z","iopub.execute_input":"2021-11-09T18:38:54.159288Z","iopub.status.idle":"2021-11-09T18:38:58.217437Z","shell.execute_reply.started":"2021-11-09T18:38:54.159249Z","shell.execute_reply":"2021-11-09T18:38:58.216594Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"'''\nFor each topic, we will explore the words occuring in that topic and its relative weight\n'''\nfor idx, topic in lda_model.print_topics(-1):\n    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-11-09T19:18:32.982974Z","iopub.execute_input":"2021-11-09T19:18:32.983775Z","iopub.status.idle":"2021-11-09T19:18:33.087227Z","shell.execute_reply.started":"2021-11-09T19:18:32.983696Z","shell.execute_reply":"2021-11-09T19:18:33.086158Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# University Recommender\n","metadata":{}},{"cell_type":"code","source":"norm_corpus = data\nnorm_corpus[:2]","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:40:28.270067Z","iopub.execute_input":"2021-11-09T18:40:28.270383Z","iopub.status.idle":"2021-11-09T18:40:28.373130Z","shell.execute_reply.started":"2021-11-09T18:40:28.270348Z","shell.execute_reply":"2021-11-09T18:40:28.371900Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\ntfidf_matrix = tf.fit_transform(norm_corpus)\ntfidf_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:40:36.737430Z","iopub.execute_input":"2021-11-09T18:40:36.737753Z","iopub.status.idle":"2021-11-09T18:40:36.992463Z","shell.execute_reply.started":"2021-11-09T18:40:36.737720Z","shell.execute_reply":"2021-11-09T18:40:36.990957Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## Compute Pairwise Document Similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndoc_sim = cosine_similarity(tfidf_matrix)\ndoc_sim_df = pd.DataFrame(doc_sim)\ndoc_sim_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:41:11.047558Z","iopub.execute_input":"2021-11-09T18:41:11.047880Z","iopub.status.idle":"2021-11-09T18:41:11.191242Z","shell.execute_reply.started":"2021-11-09T18:41:11.047847Z","shell.execute_reply":"2021-11-09T18:41:11.190579Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"df1.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:42:04.799146Z","iopub.execute_input":"2021-11-09T18:42:04.799546Z","iopub.status.idle":"2021-11-09T18:42:04.943228Z","shell.execute_reply.started":"2021-11-09T18:42:04.799504Z","shell.execute_reply":"2021-11-09T18:42:04.941872Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Get List of Undergraduates","metadata":{}},{"cell_type":"code","source":"underg_list = df1['undergraduate'].values\nunderg_list[:5], underg_list.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:46:07.818473Z","iopub.execute_input":"2021-11-09T18:46:07.818802Z","iopub.status.idle":"2021-11-09T18:46:07.907642Z","shell.execute_reply.started":"2021-11-09T18:46:07.818768Z","shell.execute_reply":"2021-11-09T18:46:07.906601Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Find Top Similar Undergraduate for an Undergraduate Core\n\nLet's take `derecho` the most popular underg the the dataframe above and try and find the most similar undergraduates which can be recommended","metadata":{}},{"cell_type":"code","source":"underg_idx = np.where(underg_list == 'derecho')[0][0]\nunderg_idx","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:47:01.863898Z","iopub.execute_input":"2021-11-09T18:47:01.864661Z","iopub.status.idle":"2021-11-09T18:47:01.972687Z","shell.execute_reply.started":"2021-11-09T18:47:01.864605Z","shell.execute_reply":"2021-11-09T18:47:01.971446Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"**Get similarities**","metadata":{}},{"cell_type":"code","source":"underg_similarities = doc_sim_df.iloc[underg_idx].values\nunderg_similarities","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:49:33.562032Z","iopub.execute_input":"2021-11-09T18:49:33.562348Z","iopub.status.idle":"2021-11-09T18:49:33.668785Z","shell.execute_reply.started":"2021-11-09T18:49:33.562316Z","shell.execute_reply":"2021-11-09T18:49:33.667658Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"**Get top 5 IDs**","metadata":{}},{"cell_type":"code","source":"similar_underg_idxs = np.argsort(-underg_similarities)[1:6]\nsimilar_underg_idxs","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:50:37.761233Z","iopub.execute_input":"2021-11-09T18:50:37.761543Z","iopub.status.idle":"2021-11-09T18:50:37.851263Z","shell.execute_reply.started":"2021-11-09T18:50:37.761510Z","shell.execute_reply":"2021-11-09T18:50:37.850210Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"**Get top 5 similar undergraduates**","metadata":{}},{"cell_type":"code","source":"similar_underg = underg_list[similar_underg_idxs]\nsimilar_underg","metadata":{"execution":{"iopub.status.busy":"2021-11-09T18:52:12.037338Z","iopub.execute_input":"2021-11-09T18:52:12.037657Z","iopub.status.idle":"2021-11-09T18:52:12.131067Z","shell.execute_reply.started":"2021-11-09T18:52:12.037626Z","shell.execute_reply":"2021-11-09T18:52:12.129924Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Build a movie recommender function to recommend top 5 similar Undergraduate to an Undergraduate\n\nThe undergraduate title, undergraduate title list and document similarity matrix dataframe will be given as inputs to the function","metadata":{}},{"cell_type":"code","source":"def underg_recommender(underg_title, undergs= underg_list, doc_sims=doc_sim_df):\n    # find underg id\n    underg_idx = np.where(undergs == underg_title)[0][0]\n    # get underg similarities\n    underg_similarities = doc_sims.iloc[underg_idx].values\n    # get top 5 similar underg IDs\n    similar_underg_idxs = np.argsort(-underg_similarities)[1:6]\n    # get top 5 undergs\n    similar_undergs = undergs[similar_underg_idxs]\n    # return the top 5 undergs\n    return similar_undergs","metadata":{"execution":{"iopub.status.busy":"2021-11-09T19:03:17.632374Z","iopub.execute_input":"2021-11-09T19:03:17.632698Z","iopub.status.idle":"2021-11-09T19:03:17.718912Z","shell.execute_reply.started":"2021-11-09T19:03:17.632665Z","shell.execute_reply":"2021-11-09T19:03:17.717469Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"df1['undergraduate'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T19:02:15.846740Z","iopub.execute_input":"2021-11-09T19:02:15.847046Z","iopub.status.idle":"2021-11-09T19:02:15.934420Z","shell.execute_reply.started":"2021-11-09T19:02:15.847013Z","shell.execute_reply":"2021-11-09T19:02:15.933467Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"underg = 'administracion'\nprint('undergraduate:', underg)\nprint('Top 5 recommended Undergraduates:', underg_recommender(underg_title=underg, undergs=underg_list, doc_sims=doc_sim_df))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-09T19:57:23.019644Z","iopub.execute_input":"2021-11-09T19:57:23.020013Z","iopub.status.idle":"2021-11-09T19:57:23.117142Z","shell.execute_reply.started":"2021-11-09T19:57:23.019979Z","shell.execute_reply":"2021-11-09T19:57:23.116010Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}