{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broadband-processor",
   "metadata": {},
   "source": [
    "### Cleaning data on Career Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "refined-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits to Victor for the code\n",
    "# Import libraries\n",
    "\n",
    "# basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import ast\n",
    "pd.set_option('display.max_rows', 500) # to show more rows.\n",
    "\n",
    "# for translation\n",
    "import sys\n",
    "from Translate_data import translate_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "czech-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estu_tipodocumento</th>\n",
       "      <th>estu_nacionalidad</th>\n",
       "      <th>estu_genero</th>\n",
       "      <th>estu_fechanacimiento</th>\n",
       "      <th>estu_exterior</th>\n",
       "      <th>periodo</th>\n",
       "      <th>estu_consecutivo</th>\n",
       "      <th>estu_estadocivil</th>\n",
       "      <th>estu_estudiante</th>\n",
       "      <th>estu_pais_reside</th>\n",
       "      <th>...</th>\n",
       "      <th>punt_biologia</th>\n",
       "      <th>punt_quimica</th>\n",
       "      <th>punt_fisica</th>\n",
       "      <th>punt_ciencias_sociales</th>\n",
       "      <th>punt_filosofia</th>\n",
       "      <th>punt_ingles</th>\n",
       "      <th>desemp_ingles</th>\n",
       "      <th>profundiza</th>\n",
       "      <th>puntaje_prof</th>\n",
       "      <th>desemp_prof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TI</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>M</td>\n",
       "      <td>30/07/1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20134</td>\n",
       "      <td>EK201340233804</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>ESTUDIANTE</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>A-</td>\n",
       "      <td>PUNT_INTERDISC_MEDIOAMBIENTE</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>M</td>\n",
       "      <td>13/04/1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20133</td>\n",
       "      <td>EK201330220754</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>ESTUDIANTE</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>PUNT_PROFUNDIZA_LENGUAJE</td>\n",
       "      <td>6.0</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>F</td>\n",
       "      <td>08/12/1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20134</td>\n",
       "      <td>EK201340246502</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>ESTUDIANTE</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>A-</td>\n",
       "      <td>PUNT_PROFUNDIZA_BIOLOGIA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  estu_tipodocumento estu_nacionalidad estu_genero estu_fechanacimiento  \\\n",
       "0                 TI          COLOMBIA           M           30/07/1996   \n",
       "1                 CC          COLOMBIA           M           13/04/1994   \n",
       "2                 CC          COLOMBIA           F           08/12/1991   \n",
       "\n",
       "  estu_exterior  periodo estu_consecutivo estu_estadocivil estu_estudiante  \\\n",
       "0           NaN    20134   EK201340233804          Soltero      ESTUDIANTE   \n",
       "1           NaN    20133   EK201330220754          Soltero      ESTUDIANTE   \n",
       "2           NaN    20134   EK201340246502          Soltero      ESTUDIANTE   \n",
       "\n",
       "  estu_pais_reside  ... punt_biologia punt_quimica  punt_fisica  \\\n",
       "0         COLOMBIA  ...          39.0         42.0         33.0   \n",
       "1         COLOMBIA  ...          52.0         52.0         54.0   \n",
       "2         COLOMBIA  ...          50.0         51.0         28.0   \n",
       "\n",
       "  punt_ciencias_sociales  punt_filosofia punt_ingles  desemp_ingles  \\\n",
       "0                   33.0            29.0        38.0             A-   \n",
       "1                   44.0            47.0        51.0             A1   \n",
       "2                   46.0            45.0        43.0             A-   \n",
       "\n",
       "                     profundiza puntaje_prof desemp_prof  \n",
       "0  PUNT_INTERDISC_MEDIOAMBIENTE         49.0         NaN  \n",
       "1      PUNT_PROFUNDIZA_LENGUAJE          6.0          II  \n",
       "2      PUNT_PROFUNDIZA_BIOLOGIA          5.0           I  \n",
       "\n",
       "[3 rows x 143 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "df_raw = pd.read_csv('saber_combined_all_fields.csv')\n",
    "df_raw = df_raw.drop(columns = 'Unnamed: 0')\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "configured-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>your_type_of_document</th>\n",
       "      <th>your_nationality</th>\n",
       "      <th>your_gender</th>\n",
       "      <th>your_birthdate</th>\n",
       "      <th>your_foreigner</th>\n",
       "      <th>period</th>\n",
       "      <th>your_consecutive</th>\n",
       "      <th>your_marital_status</th>\n",
       "      <th>your_student</th>\n",
       "      <th>your_country_resides</th>\n",
       "      <th>...</th>\n",
       "      <th>score_biology_saber_11</th>\n",
       "      <th>score_chemistry_saber_11</th>\n",
       "      <th>score_physics_saber_11</th>\n",
       "      <th>score_social_science_saber_11</th>\n",
       "      <th>score_philosophy_saber_11</th>\n",
       "      <th>score_english_saber_11</th>\n",
       "      <th>score_english_saber_11_category</th>\n",
       "      <th>optative_field_saber_11</th>\n",
       "      <th>score_optative_saber_11</th>\n",
       "      <th>optative_category_saber_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TI</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>M</td>\n",
       "      <td>30/07/1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20134</td>\n",
       "      <td>EK201340233804</td>\n",
       "      <td>Single</td>\n",
       "      <td>STUDENT</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>A-</td>\n",
       "      <td>SCORE_INTERDISC_ENVIRONMENT</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>M</td>\n",
       "      <td>13/04/1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20133</td>\n",
       "      <td>EK201330220754</td>\n",
       "      <td>Single</td>\n",
       "      <td>STUDENT</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>SCORE_DEEPEN_LANGUAGE</td>\n",
       "      <td>6.0</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>F</td>\n",
       "      <td>08/12/1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20134</td>\n",
       "      <td>EK201340246502</td>\n",
       "      <td>Single</td>\n",
       "      <td>STUDENT</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>A-</td>\n",
       "      <td>SCORE_DEEPEN_BIOLOGY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  your_type_of_document your_nationality your_gender your_birthdate  \\\n",
       "0                    TI         COLOMBIA           M     30/07/1996   \n",
       "1                    CC         COLOMBIA           M     13/04/1994   \n",
       "2                    CC         COLOMBIA           F     08/12/1991   \n",
       "\n",
       "  your_foreigner  period your_consecutive your_marital_status your_student  \\\n",
       "0            NaN   20134   EK201340233804              Single      STUDENT   \n",
       "1            NaN   20133   EK201330220754              Single      STUDENT   \n",
       "2            NaN   20134   EK201340246502              Single      STUDENT   \n",
       "\n",
       "  your_country_resides  ... score_biology_saber_11 score_chemistry_saber_11  \\\n",
       "0             COLOMBIA  ...                   39.0                     42.0   \n",
       "1             COLOMBIA  ...                   52.0                     52.0   \n",
       "2             COLOMBIA  ...                   50.0                     51.0   \n",
       "\n",
       "   score_physics_saber_11 score_social_science_saber_11  \\\n",
       "0                    33.0                          33.0   \n",
       "1                    54.0                          44.0   \n",
       "2                    28.0                          46.0   \n",
       "\n",
       "   score_philosophy_saber_11 score_english_saber_11  \\\n",
       "0                       29.0                   38.0   \n",
       "1                       47.0                   51.0   \n",
       "2                       45.0                   43.0   \n",
       "\n",
       "   score_english_saber_11_category      optative_field_saber_11  \\\n",
       "0                               A-  SCORE_INTERDISC_ENVIRONMENT   \n",
       "1                               A1        SCORE_DEEPEN_LANGUAGE   \n",
       "2                               A-         SCORE_DEEPEN_BIOLOGY   \n",
       "\n",
       "  score_optative_saber_11 optative_category_saber_11  \n",
       "0                    49.0                        NaN  \n",
       "1                     6.0                         II  \n",
       "2                     5.0                          I  \n",
       "\n",
       "[3 rows x 143 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translate data\n",
    "df = translate_data(df_raw, 'spanish', 'english')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inside-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling Department\n",
    "\n",
    "# - - - correct code - - - \n",
    "# Change code from float to int\n",
    "df['your_dept_code_resides'] = df[['your_dept_code_resides']].apply(np.int64).astype(str)\n",
    "df['your_dept_code_resides.1'] = df[['your_dept_code_resides.1']].apply(np.int64).astype(str)\n",
    "\n",
    "# two-digit code for Department (Colombian States)\n",
    "df['your_dept_code_resides'] = [\"0\"+i if len(i)==1 else i for i in df['your_dept_code_resides']]\n",
    "df['your_dept_code_resides.1'] = [\"0\"+i if len(i)==1 else i for i in df['your_dept_code_resides.1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "located-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling Municipality\n",
    "\n",
    "# - - - correct name - - - \n",
    "import re\n",
    "municipality_list = list(df['cole_municipality_location'].unique()) + \\\n",
    "                    list(df['your_municipality_resides'].unique()) + \\\n",
    "                    list(df['your_inst_municipality'].unique()) + \\\n",
    "                    list(df['your_municipality_resides.1'].unique())\n",
    "\n",
    "municipality_list = pd.DataFrame(data=municipality_list, columns=['Name'])#.unique()\n",
    "municipality_list = list(municipality_list.Name.unique())\n",
    "municipality_list = [str(i) for i in municipality_list]\n",
    "municipality_list = sorted(municipality_list)\n",
    "municipality_values = sorted(municipality_list)\n",
    "\n",
    "municipality_values = [re.sub(r'BOGOTÁ, D.C.', 'BOGOTÁ D.C.', mun) for mun in municipality_values]\n",
    "municipality_values = [re.sub(r'CARTAGENA$', 'CARTAGENA DE INDIAS', mun) for mun in municipality_values]\n",
    "municipality_values = [re.sub(r'CHIQUINQUIRA$', 'CHIQUINQUIRÁ', mun) for mun in municipality_values]\n",
    "municipality_values = [re.sub(r'CIÉNEGA$', 'CIÉNAGA', mun) for mun in municipality_values]\n",
    "municipality_values = [re.sub(r'PUERTO ASIS$', 'PUERTO ASÍS', mun) for mun in municipality_values]\n",
    "municipality_values = [re.sub(r'POPAYAN$', 'POPAYÁN', mun) for mun in municipality_values]\n",
    "municipality_values = [re.sub(r'FACATATIVÁ$', 'FACATATIVA', mun) for mun in municipality_values]\n",
    "\n",
    "zip_iterator = zip(municipality_list, municipality_values) # Get pairs of elements\n",
    "municipality_dict = dict(zip_iterator)  # Convert to dictionary\n",
    "\n",
    "municipality_columns = ['cole_municipality_location', 'your_municipality_resides',\n",
    "                        'your_inst_municipality', 'your_municipality_resides.1']\n",
    "\n",
    "for col in municipality_columns:\n",
    "    df[col] = df[col].map(municipality_dict)\n",
    "    \n",
    "# - - - correct code - - - \n",
    "# Change code from float to int\n",
    "df['your_municipality_code_resides'] = df[['your_municipality_code_resides']].apply(np.int64).astype(str)\n",
    "df['your_municipality_code_resides.1'] = df[['your_municipality_code_resides.1']].apply(np.int64).astype(str)\n",
    "\n",
    "# two-digit code for Department (Colombian States)\n",
    "df['your_municipality_code_resides'] = [\"0\"+i if len(i)==4 else i for i in df['your_municipality_code_resides']]\n",
    "df['your_municipality_code_resides.1'] = [\"0\"+i if len(i)==4 else i for i in df['your_municipality_code_resides.1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beneficial-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data on the career field\n",
    "# dictionary of categorical variables\n",
    "import urllib.request as urllib2\n",
    "import ast\n",
    "contents = str(\"\")\n",
    "for line in urllib2.urlopen(\"https://raw.githubusercontent.com/vcuspinera/Datasets/main/omdena/colombia-career-recommender-system/translate_cat.txt\"):\n",
    "    contents += str(line)[2:-3]\n",
    "contents += \"}\"\n",
    "char_to_replace = {\n",
    "    \"\\\\r\": \"\", \"\\\\\": \"\", # characters\n",
    "    \"xc3x81\": \"Á\", \"xc3x89\": \"É\", \"xc3x8d\": \"Í\", \"xc3x93\": \"Ó\", \"xc3x9a\": \"Ú\", \"xc3x9c\": \"Ü\", \"xc3x91\": \"Ñ\", # capital letters\n",
    "    \"xc3xa1\": \"á\", \"xc3xa9\": \"é\", \"xc3xad\": \"í\", \"xc3xb3\": \"ó\", \"xc3xba\": \"ú\", \"xc3xb1\": \"ñ\" # lowercase letters\n",
    "}\n",
    "for key, value in char_to_replace.items():\n",
    "    contents = contents.replace(key, value)\n",
    "dic_cat = ast.literal_eval(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specialized-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the undergraduate core field variable\n",
    "df['your_undergraduate_core_field'] = df[['your_undergraduate_core']].replace(dic_cat['your_undergraduate_core_field'])\n",
    "# Change NULL values to UNCLASSIFIED label\n",
    "df['your_undergraduate_core'] = df['your_undergraduate_core'].replace(np.nan, \"UNCLASSIFIED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bound-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADMINISTRATION                                  35790\n",
       "LAW                                             15263\n",
       "PUBLIC ACCOUNTING                               14334\n",
       "EDUCATION                                       14219\n",
       "INDUSTRIAL ENGINEERING                          10660\n",
       "PSYCHOLOGY                                      10518\n",
       "UNCLASSIFIED                                     8614\n",
       "ENVIRONMENTAL, SANITARY ENGINEERING              8231\n",
       "CIVIL ENGINEERING                                7736\n",
       "SOCIAL COMMUNICATION, JOURNALISM                 7479\n",
       "ECONOMY                                          7243\n",
       "COMPUTER SYSTEMS, TELEMATICS ENGINEERING         6805\n",
       "MECHANICAL ENGINEERING                           5382\n",
       "DESIGN                                           5263\n",
       "ARCHITECTURE                                     3969\n",
       "SOCIOLOGY, SOCIAL WORK                           3832\n",
       "NURSING                                          3440\n",
       "ELECTRONIC ENGINEERING, TELECOMMUNICATIONS       2845\n",
       "MEDICINE                                         2764\n",
       "SUPERIOR NORMALS                                 2655\n",
       "THERAPIES                                        2575\n",
       "MILITARY OR POLICE TRAINING                      2370\n",
       "POLITICAL SCIENCE, INTERNATIONAL RELATIONS       2061\n",
       "CHEMICAL ENGINEERING                             1853\n",
       "AGRONOMY                                         1801\n",
       "BIOLOGY, MICROBIOLOGY                            1607\n",
       "PLASTIC AND VISUAL ARTS                          1361\n",
       "MINING, METALLURGY ENGINEERING                   1226\n",
       "PUBLIC HEALTH                                    1156\n",
       "OTHER ENGINEERING                                1120\n",
       "VETERINARY MEDICINE                              1077\n",
       "ADVERTISING                                       982\n",
       "ELECTRICAL ENGINEERING                            979\n",
       "CHEMISTRY                                         972\n",
       "AGROINDUSTRIAL AND FOOD ENGINEERING               942\n",
       "SPORTS, PHYSICAL EDUCATION AND RECREATION         899\n",
       "MODERN LANGUAGES, LITERATURE, LINGUISTICS         827\n",
       "ODONTOLOGY                                        817\n",
       "SURGICAL INSTRUMENTATION                          786\n",
       "DENTISTRY                                         763\n",
       "ZOOTECHNY                                         756\n",
       "AGRONOMIC AND LIVESTOCK ENGINEERING               749\n",
       "ADMINISTRATIVE ENGINEERING                        709\n",
       "GEOGRAPHY, HISTORY                                675\n",
       "BACTERIOLOGY                                      607\n",
       "NUTRITION AND DIET                                589\n",
       "GEOLOGY, OTHER NATURAL SCIENCE PROGRAMS           565\n",
       "LIBRARY, OTHERS OF SOCIAL AND HUMAN SCIENCES      530\n",
       "BIOMEDICAL ENGINEERING                            528\n",
       "AGRICULTURAL, FORESTRY ENGINEERING                512\n",
       "MUSIC                                             444\n",
       "ANTHROPOLOGY, LIBERAL ARTS                        402\n",
       "MATH, STATISTICS                                  392\n",
       "OTHER PROGRAMS ASSOCIATED WITH FINE ARTS          372\n",
       "PHILOSOPHY, THEOLOGY                              336\n",
       "OPTOMETRY, OTHER HEALTH SCIENCE PROGRAMS          273\n",
       "PHYSICS                                           191\n",
       "REPRESENTATIVE ARTS                               164\n",
       "Name: your_undergraduate_core, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['your_undergraduate_core'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "concrete-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['your_undergraduate_core'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "asian-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212010, 144)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "federal-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Unclassified category\n",
    "df = df[df['your_undergraduate_core']!='UNCLASSIFIED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "whole-radius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203396, 144)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-allen",
   "metadata": {},
   "source": [
    "The 8614 rows containing the unclassified category have been removed. We still have plenty of data to build ou recommendation model on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-utilization",
   "metadata": {},
   "source": [
    "### Selecting the features to Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-communications",
   "metadata": {},
   "source": [
    "I will select all the saber 11 scores as the input to the model. The 'your_undergraduate_core_field' will be used as the target. There is high imbalance of categories still, which will be handled later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comparable-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['score_language_saber_11', 'score_mathematics_saber_11', 'score_biology_saber_11', 'score_chemistry_saber_11',\n",
    "                 'score_physics_saber_11', 'score_social_science_saber_11', 'score_philosophy_saber_11', \n",
    "                  'score_english_saber_11', 'your_undergraduate_core']\n",
    "target_feature = 'your_undergraduate_core'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "light-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[input_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "suffering-repeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_language_saber_11          False\n",
       "score_mathematics_saber_11       False\n",
       "score_biology_saber_11           False\n",
       "score_chemistry_saber_11         False\n",
       "score_physics_saber_11           False\n",
       "score_social_science_saber_11    False\n",
       "score_philosophy_saber_11        False\n",
       "score_english_saber_11           False\n",
       "your_undergraduate_core          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fewer-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = data['your_undergraduate_core']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "raising-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data.drop('your_undergraduate_core', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "invisible-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_language_saber_11</th>\n",
       "      <th>score_mathematics_saber_11</th>\n",
       "      <th>score_biology_saber_11</th>\n",
       "      <th>score_chemistry_saber_11</th>\n",
       "      <th>score_physics_saber_11</th>\n",
       "      <th>score_social_science_saber_11</th>\n",
       "      <th>score_philosophy_saber_11</th>\n",
       "      <th>score_english_saber_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score_language_saber_11  score_mathematics_saber_11  \\\n",
       "0                     32.0                        43.0   \n",
       "1                     48.0                        64.0   \n",
       "\n",
       "   score_biology_saber_11  score_chemistry_saber_11  score_physics_saber_11  \\\n",
       "0                    39.0                      42.0                    33.0   \n",
       "1                    52.0                      52.0                    54.0   \n",
       "\n",
       "   score_social_science_saber_11  score_philosophy_saber_11  \\\n",
       "0                           33.0                       29.0   \n",
       "1                           44.0                       47.0   \n",
       "\n",
       "   score_english_saber_11  \n",
       "0                    38.0  \n",
       "1                    51.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-absence",
   "metadata": {},
   "source": [
    "### Preprocessing the Data for the Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "flexible-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, val and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size = 0.05)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "worthy-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177767, 8) (177767,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "worse-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15459, 8) (15459,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stupid-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10170, 8) (10170,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "joint-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "broad-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the input features\n",
    "def scale_input(X, scaler):\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "driving-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = scale_input(X_train, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "taken-suspension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.87003763, -0.6357859 , -0.55771466, -0.88359363, -0.8941784 ,\n",
       "       -0.78527545,  0.29711551, -0.69545886])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "visible-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_s = scale_input(X_test, scaler)\n",
    "X_val_s = scale_input(X_val, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "incident-parent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177767, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "necessary-capture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surface-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can encode the labels\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "excess-vaccine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exotic-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e = le.transform(y_train)\n",
    "y_val_e = le.transform(y_val)\n",
    "y_test_e = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dependent-nicholas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 49, 46, ...,  0, 19,  0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pursuant-happiness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 17,  6,  ...,  0, 47, 35])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.tensor(y_train_e, dtype=torch.long)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "first-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = torch.tensor(y_val_e, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test_e, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "viral-albany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46, 49, 46,  6, 18,  2, 29, 19, 14, 49,  0, 19,  0, 39, 29, 26, 26, 29,\n",
       "         0,  0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "indonesian-grill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ADMINISTRATION',\n",
       " 'ADMINISTRATIVE ENGINEERING',\n",
       " 'ADVERTISING',\n",
       " 'AGRICULTURAL, FORESTRY ENGINEERING',\n",
       " 'AGROINDUSTRIAL AND FOOD ENGINEERING',\n",
       " 'AGRONOMIC AND LIVESTOCK ENGINEERING',\n",
       " 'AGRONOMY',\n",
       " 'ANTHROPOLOGY, LIBERAL ARTS',\n",
       " 'ARCHITECTURE',\n",
       " 'BACTERIOLOGY',\n",
       " 'BIOLOGY, MICROBIOLOGY',\n",
       " 'BIOMEDICAL ENGINEERING',\n",
       " 'CHEMICAL ENGINEERING',\n",
       " 'CHEMISTRY',\n",
       " 'CIVIL ENGINEERING',\n",
       " 'COMPUTER SYSTEMS, TELEMATICS ENGINEERING',\n",
       " 'DENTISTRY',\n",
       " 'DESIGN',\n",
       " 'ECONOMY',\n",
       " 'EDUCATION',\n",
       " 'ELECTRICAL ENGINEERING',\n",
       " 'ELECTRONIC ENGINEERING, TELECOMMUNICATIONS',\n",
       " 'ENVIRONMENTAL, SANITARY ENGINEERING',\n",
       " 'GEOGRAPHY, HISTORY',\n",
       " 'GEOLOGY, OTHER NATURAL SCIENCE PROGRAMS',\n",
       " 'INDUSTRIAL ENGINEERING',\n",
       " 'LAW',\n",
       " 'LIBRARY, OTHERS OF SOCIAL AND HUMAN SCIENCES',\n",
       " 'MATH, STATISTICS',\n",
       " 'MECHANICAL ENGINEERING',\n",
       " 'MEDICINE',\n",
       " 'MILITARY OR POLICE TRAINING',\n",
       " 'MINING, METALLURGY ENGINEERING',\n",
       " 'MODERN LANGUAGES, LITERATURE, LINGUISTICS',\n",
       " 'MUSIC',\n",
       " 'NURSING',\n",
       " 'NUTRITION AND DIET',\n",
       " 'ODONTOLOGY',\n",
       " 'OPTOMETRY, OTHER HEALTH SCIENCE PROGRAMS',\n",
       " 'OTHER ENGINEERING',\n",
       " 'OTHER PROGRAMS ASSOCIATED WITH FINE ARTS',\n",
       " 'PHILOSOPHY, THEOLOGY',\n",
       " 'PHYSICS',\n",
       " 'PLASTIC AND VISUAL ARTS',\n",
       " 'POLITICAL SCIENCE, INTERNATIONAL RELATIONS',\n",
       " 'PSYCHOLOGY',\n",
       " 'PUBLIC ACCOUNTING',\n",
       " 'PUBLIC HEALTH',\n",
       " 'REPRESENTATIVE ARTS',\n",
       " 'SOCIAL COMMUNICATION, JOURNALISM',\n",
       " 'SOCIOLOGY, SOCIAL WORK',\n",
       " 'SPORTS, PHYSICAL EDUCATION AND RECREATION',\n",
       " 'SUPERIOR NORMALS',\n",
       " 'SURGICAL INSTRUMENTATION',\n",
       " 'THERAPIES',\n",
       " 'VETERINARY MEDICINE',\n",
       " 'ZOOTECHNY']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list(le.classes_)))\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "japanese-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "developmental-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert the input arrays to tensor\n",
    "# First convert to float\n",
    "X_train_s = X_train_s.astype(np.float32)\n",
    "X_val_s = X_val_s.astype(np.float32)\n",
    "X_test_s = X_test_s.astype(np.float32)\n",
    "\n",
    "X_train_t = torch.tensor(X_train_s)\n",
    "X_val_t = torch.tensor(X_val_s)\n",
    "X_test_t = torch.tensor(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "involved-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 177767, 'val': 15459}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up Torch Dataloaders\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train)\n",
    "test_dataset = TensorDataset(X_test_t, y_test)\n",
    "val_dataset = TensorDataset(X_val_t, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "administrative-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f61c0eff790>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "strategic-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2090, -0.4763, -0.0700, -1.1218,  0.4015, -0.4404, -0.2393, -0.4210])\n",
      "torch.Size([32, 8])\n",
      "tensor([35, 25,  0, 17, 46, 18,  0,  0, 14,  0, 31, 18, 50, 17,  0, 45, 49, 13,\n",
      "        14,  0, 25,  0, 25, 13, 14, 26, 44, 20, 49, 28, 26, 22])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Lets have a look at the first batch of the train_loader\n",
    "for x, y in train_loader:\n",
    "    print(x[0])\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "handmade-optimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7165,  0.4806,  1.0274,  0.4263, -0.5952,  0.0194,  0.5117,  0.4711])\n",
      "torch.Size([32, 8])\n",
      "tensor([22, 40, 29,  0, 45, 26, 46, 22, 46, 17, 26, 26, 40, 29, 35,  0, 17, 20,\n",
      "        31,  0, 46, 26, 26, 29, 22, 25, 14,  0, 44, 29, 35, 18])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Lets have a look at the first batch of the val_loader\n",
    "for x, y in val_loader:\n",
    "    print(x[0])\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "informed-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4521, -0.1573,  0.2958,  0.6645,  0.5012,  0.2493,  1.0481, -0.6268])\n",
      "torch.Size([32, 8])\n",
      "tensor([46, 49, 46,  6, 18,  2, 29, 19, 14, 49,  0, 19,  0, 39, 29, 26, 26, 29,\n",
      "         0,  0, 14, 45, 18,  0, 30, 49, 25, 14,  0, 32, 46,  0])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Lets have a look at the first batch of the test_loader\n",
    "for x, y in test_loader:\n",
    "    print(x[0])\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "behind-tribune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f61c0eff790>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7f61c0eff700>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = {'train':train_loader, 'val':val_loader}\n",
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-village",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "veterinary-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "mathematical-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationModel(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.recommender = nn.Sequential(\n",
    "            nn.Linear(in_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, out_size),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.recommender(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cordless-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "insize = 8\n",
    "outsize = 57\n",
    "model = RecommendationModel(insize, outsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "original-subsection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecommendationModel(\n",
       "  (recommender): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (16): ReLU()\n",
       "    (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (22): ReLU()\n",
       "    (23): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): Linear(in_features=64, out_features=57, bias=True)\n",
       "    (25): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "divided-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([57, 64])\n",
      "torch.Size([57])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "informal-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and generate some outputs using the model\n",
    "for x, y in train_loader:\n",
    "    out = model(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "excess-canyon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0026, 0.0086, 0.0072, 0.0389, 0.0407, 0.0082, 0.0149, 0.0440, 0.0835,\n",
       "        0.0115, 0.0131, 0.0124, 0.0268, 0.0281, 0.0189, 0.0138, 0.0116, 0.0126,\n",
       "        0.0113, 0.0141, 0.0134, 0.0117, 0.0165, 0.0286, 0.0054, 0.0219, 0.0150,\n",
       "        0.0227, 0.0104, 0.0105, 0.0122, 0.0175, 0.0110, 0.0236, 0.0059, 0.0060,\n",
       "        0.0067, 0.0068, 0.0251, 0.0117, 0.0081, 0.0163, 0.0160, 0.0135, 0.0280,\n",
       "        0.0209, 0.0143, 0.0297, 0.0073, 0.0109, 0.0133, 0.0170, 0.0259, 0.0213,\n",
       "        0.0240, 0.0236, 0.0042], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "funky-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the device to cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-murder",
   "metadata": {},
   "source": [
    "### Setting up the Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-smooth",
   "metadata": {},
   "source": [
    "Focal loss,originally developed for handling extreme foreground-background class imbalance in object detection algorithms, could be used as an alternative for cross-entropy loss when you have imbalanced datasets.\n",
    "original paper: https://arxiv.org/abs/1708.02002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "conventional-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight, reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, inp, target):\n",
    "        ce_loss = F.cross_entropy(inp, target, reduction=self.reduction, weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1-pt)**self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dramatic-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FocalLoss()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_loss = FocalLoss()\n",
    "fc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "infinite-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and generate some outputs and test the loss fn using the model\n",
    "for x, y in train_loader:\n",
    "    out = model(x)\n",
    "    loss = fc_loss(out, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "complimentary-perception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 40, 25,  0, 29, 19,  0,  0, 22, 45, 33, 46, 25, 46,  0,  0, 45, 31,\n",
       "        35, 23,  2, 19,  0, 19, 18,  0,  0, 25, 49,  0, 45,  0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "hydraulic-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 18, 22, 50, 47,  1, 43, 56, 31, 39,  8, 44, 12, 52, 51,  7, 46,  8,\n",
       "        27, 50, 19,  4, 54, 44, 47,  3, 32, 16, 53, 52, 31, 29])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, preds = torch.max(out, 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "completed-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9023, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "governing-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets write the funtion for the training loop\n",
    "import time\n",
    "import copy\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-thompson",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "spatial-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-thomson",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "played-north",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 3.8290 Acc: 0.1681\n",
      "val Loss: 3.8130 Acc: 0.1805\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 3.8197 Acc: 0.1741\n",
      "val Loss: 3.8121 Acc: 0.1811\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 3.8172 Acc: 0.1764\n",
      "val Loss: 3.8134 Acc: 0.1800\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 3.8170 Acc: 0.1766\n",
      "val Loss: 3.8129 Acc: 0.1805\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 3.8169 Acc: 0.1766\n",
      "val Loss: 3.8128 Acc: 0.1804\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 3.8167 Acc: 0.1768\n",
      "val Loss: 3.8118 Acc: 0.1813\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 3.8160 Acc: 0.1775\n",
      "val Loss: 3.8119 Acc: 0.1813\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1772\n",
      "val Loss: 3.8126 Acc: 0.1806\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 3.8160 Acc: 0.1774\n",
      "val Loss: 3.8133 Acc: 0.1800\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 3.8187 Acc: 0.1750\n",
      "val Loss: 3.8140 Acc: 0.1794\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 3.8163 Acc: 0.1771\n",
      "val Loss: 3.8134 Acc: 0.1799\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1773\n",
      "val Loss: 3.8123 Acc: 0.1809\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 3.8164 Acc: 0.1770\n",
      "val Loss: 3.8130 Acc: 0.1803\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 3.8169 Acc: 0.1766\n",
      "val Loss: 3.8134 Acc: 0.1799\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 3.8165 Acc: 0.1770\n",
      "val Loss: 3.8124 Acc: 0.1809\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 3.8168 Acc: 0.1767\n",
      "val Loss: 3.8127 Acc: 0.1806\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 3.8165 Acc: 0.1770\n",
      "val Loss: 3.8122 Acc: 0.1810\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 3.8165 Acc: 0.1770\n",
      "val Loss: 3.8132 Acc: 0.1802\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 3.8163 Acc: 0.1772\n",
      "val Loss: 3.8130 Acc: 0.1804\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 3.8167 Acc: 0.1767\n",
      "val Loss: 3.8132 Acc: 0.1801\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 3.8170 Acc: 0.1765\n",
      "val Loss: 3.8126 Acc: 0.1807\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 3.8169 Acc: 0.1766\n",
      "val Loss: 3.8127 Acc: 0.1805\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 3.8166 Acc: 0.1768\n",
      "val Loss: 3.8121 Acc: 0.1813\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 3.8164 Acc: 0.1770\n",
      "val Loss: 3.8132 Acc: 0.1801\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 3.8172 Acc: 0.1764\n",
      "val Loss: 3.8137 Acc: 0.1796\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 3.8166 Acc: 0.1768\n",
      "val Loss: 3.8131 Acc: 0.1802\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 3.8169 Acc: 0.1766\n",
      "val Loss: 3.8146 Acc: 0.1787\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 3.8164 Acc: 0.1771\n",
      "val Loss: 3.8141 Acc: 0.1792\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 3.8165 Acc: 0.1770\n",
      "val Loss: 3.8134 Acc: 0.1800\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 3.8163 Acc: 0.1772\n",
      "val Loss: 3.8128 Acc: 0.1804\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 3.8168 Acc: 0.1767\n",
      "val Loss: 3.8145 Acc: 0.1788\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 3.8163 Acc: 0.1772\n",
      "val Loss: 3.8130 Acc: 0.1802\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 3.8161 Acc: 0.1773\n",
      "val Loss: 3.8136 Acc: 0.1796\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 3.8159 Acc: 0.1775\n",
      "val Loss: 3.8124 Acc: 0.1808\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 3.8161 Acc: 0.1774\n",
      "val Loss: 3.8126 Acc: 0.1806\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1773\n",
      "val Loss: 3.8131 Acc: 0.1802\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1772\n",
      "val Loss: 3.8121 Acc: 0.1812\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 3.8161 Acc: 0.1773\n",
      "val Loss: 3.8124 Acc: 0.1808\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 3.8161 Acc: 0.1773\n",
      "val Loss: 3.8120 Acc: 0.1813\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 3.8160 Acc: 0.1774\n",
      "val Loss: 3.8128 Acc: 0.1805\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 3.8158 Acc: 0.1776\n",
      "val Loss: 3.8130 Acc: 0.1803\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 3.8159 Acc: 0.1775\n",
      "val Loss: 3.8129 Acc: 0.1803\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1773\n",
      "val Loss: 3.8129 Acc: 0.1803\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 3.8163 Acc: 0.1771\n",
      "val Loss: 3.8130 Acc: 0.1802\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1773\n",
      "val Loss: 3.8130 Acc: 0.1803\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 3.8164 Acc: 0.1771\n",
      "val Loss: 3.8123 Acc: 0.1809\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1773\n",
      "val Loss: 3.8122 Acc: 0.1811\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 3.8162 Acc: 0.1773\n",
      "val Loss: 3.8123 Acc: 0.1809\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 3.8159 Acc: 0.1776\n",
      "val Loss: 3.8130 Acc: 0.1803\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 3.8160 Acc: 0.1774\n",
      "val Loss: 3.8116 Acc: 0.1816\n",
      "\n",
      "Training complete in 16m 58s\n",
      "Best val Acc: 0.181577\n"
     ]
    }
   ],
   "source": [
    "model_final = train_model(model, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save('./model_final.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
